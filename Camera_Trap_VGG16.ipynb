{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792d88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535e7b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "\n",
    "\n",
    "# Data path and directories\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'Dataset/train_validation'))\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "data_count = []\n",
    "\n",
    "for animal in data_dir.glob('*'):\n",
    "    name = str(animal).split(\"\\\\\")[-1]\n",
    "    number = len(list(data_dir.glob(f'*{name}/*.jpg')))\n",
    "    data_count.append((name, number))\n",
    "\n",
    "print(data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the class names\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*')])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Validation dataset\n",
    "\n",
    "# Create the image_generator\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Create the Training dataset generator\n",
    "train_data_gen = image_generator.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "# Crate the validation dataset generator\n",
    "validation_data_gen = image_generator.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    subset='validation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, let's define a function, show_batch() for inspecting a batch\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02048888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VGG16\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(CLASS_NAMES)\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "n_epochs = 10\n",
    "n_steps = train_data_gen.samples // BATCH_SIZE\n",
    "n_val_steps = validation_data_gen.samples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39061912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model_base = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    ")\n",
    "\n",
    "# make the rest of the layers untrainable\n",
    "for layer in model_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add layers on top of the model a process called\n",
    "# Fine tunning\n",
    "top_model = model_base.output\n",
    "top_model = tf.keras.layers.Flatten(name=\"flatten\")(top_model)\n",
    "top_model = tf.keras.layers.Dense(1024, activation='relu')(top_model)\n",
    "top_model = tf.keras.layers.Dropout(0.2)(top_model)\n",
    "output_layer = tf.keras.layers.Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "model = Model(inputs=model_base.input, outputs=output_layer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4746ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to save the best model whilt training\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(\n",
    "    filepath='tl_model_v1.weights.best.hdf5',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Early stopping to avoid overfitting of model\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs=n_epochs,\n",
    "        validation_data=validation_data_gen,\n",
    "        steps_per_epoch=n_steps,\n",
    "        validation_steps=n_val_steps,\n",
    "        callbacks=[\n",
    "            tl_checkpoint_1\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and validation accuracies\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and validation losses\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"camera_trap_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, _ = next(validation_data_gen)\n",
    "\n",
    "prediction = model.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1567b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED_CLASS_NAMES = []\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    score = prediction[i]\n",
    "    name = CLASS_NAMES[score.argmax()]\n",
    "    PREDICTED_CLASS_NAMES.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_batch(image_batch, labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(labels[n])\n",
    "        plt.axis('off')\n",
    "        \n",
    "show_predicted_batch(image_batch, PREDICTED_CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459a36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
